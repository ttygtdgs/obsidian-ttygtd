{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56cccac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def process_video(video_path, output_csv):\n",
    "    # YOLOv8モデルの読み込み（人などの物体検出用）\n",
    "    model = YOLO('yolov8m.pt')  # 精度重視なら 'yolov8x.pt', 速度重視なら 'yolov8n.pt'\n",
    "\n",
    "    # 動画の読み込み\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # ログ保存用リスト\n",
    "    log_data = []\n",
    "    \n",
    "    # 動画の開始時刻（仮定：ファイル名やメタデータから取得する想定）\n",
    "    start_time = datetime.strptime(\"2025-04-10 17:40:27\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # フレームごとに推論を実行（トラッキング有効化）\n",
    "        # persist=True で前のフレームのIDを引き継ぐ\n",
    "        results = model.track(frame, persist=True, classes=[0], verbose=False) # class 0 is 'person'\n",
    "\n",
    "        # 現在の時刻計算\n",
    "        current_time = start_time + timedelta(seconds=frame_count / frame_rate)\n",
    "        timestamp_str = current_time.strftime(\"%H:%M:%S\")\n",
    "\n",
    "        # 検出された人数\n",
    "        num_people = 0\n",
    "        people_ids = []\n",
    "        \n",
    "        # 検出結果の解析\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes\n",
    "            track_ids = boxes.id.int().cpu().tolist()\n",
    "            # confidences = boxes.conf.float().cpu().tolist()\n",
    "            \n",
    "            num_people = len(track_ids)\n",
    "            people_ids = track_ids\n",
    "            \n",
    "            # ここで各人の座標(x,y)により「レジ前」「席」などのエリア判定が可能\n",
    "            # 例: for box, track_id in zip(boxes.xyxy, track_ids): ...\n",
    "\n",
    "        # 1秒ごとのデータをログに残す（フレームレートで割った余りが0の時など）\n",
    "        # ここでは簡易的に毎フレームのデータを間引いて処理する想定で全件追加または調整\n",
    "        if frame_count % int(frame_rate) == 0:  # 1秒に1回ログ出力\n",
    "            print(f\"Time: {timestamp_str} | Count: {num_people} | IDs: {people_ids}\")\n",
    "            log_data.append({\n",
    "                \"Timestamp\": timestamp_str,\n",
    "                \"Person_Count\": num_people,\n",
    "                \"Person_IDs\": people_ids\n",
    "            })\n",
    "\n",
    "        # （オプション）画面にバウンディングボックスを描画して表示\n",
    "        # annotated_frame = results[0].plot()\n",
    "        # cv2.imshow(\"YOLOv8 Analysis\", annotated_frame)\n",
    "        # if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        #     break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # CSVに保存\n",
    "    df = pd.DataFrame(log_data)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Analysis saved to {output_csv}\")\n",
    "\n",
    "# 実行\n",
    "# video_pathには実際の動画ファイルまたは連番画像のパスを指定\n",
    "# process_video('input_video.mp4', 'output_log.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
